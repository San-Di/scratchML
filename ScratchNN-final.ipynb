{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ScratchNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXDGNwHcRMYi8wU9w1BYpJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/San-Di/scratchML/blob/master/ScratchNN-final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ho-_CN0madV"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "from enum import Enum\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qaq4q4C6m33p"
      },
      "source": [
        "class ActivationType(Enum):\n",
        "  Relu = lambda x: np.max(X, 0)\n",
        "  Softmax = lambda x: np.exp(x)/sum(np.exp(x))\n",
        "  Sigmoid = lambda x: 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEufYeoioBFT"
      },
      "source": [
        "def forward_propagation(X, W, b, g):\n",
        "  # print(\"X\",X.shape,\"W\", W.shape)\n",
        "  z = np.dot(X, W) + b\n",
        "  a = g(z)\n",
        "  return z,a\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo2SuSE3xqQ6"
      },
      "source": [
        "def sigmoid_gradient(self, z):\n",
        "  a = self._sigmoid(z)\n",
        "  return a * (1 - a)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDZjkSdLhzsU"
      },
      "source": [
        "def backward_propagation(params, curr_layer, Y, m, last_layer):\n",
        "  A_prev = params[\"A\"+str(curr_layer - 1)]\n",
        "  \n",
        "  dZ = []\n",
        "  if curr_layer == last_layer:\n",
        "    # print(\"****** A{} = {}\".format(curr_layer, params[\"A\"+str(curr_layer)].shape) )\n",
        "    dZ = params[\"A\"+str(curr_layer)] - Y\n",
        "  else:\n",
        "    # print(\"W{} = {} \\t dZ{} = {}\".format(curr_layer, A_prev.shape, curr_layer, dZ.shape))\n",
        "    dZ = np.dot(params['dZ' + str(curr_layer + 1)], params['W' + str(curr_layer + 1)].T) \n",
        "  # print(\"A{} = {} \\t Z{} = {}\".format(curr_layer, A_prev.shape, curr_layer, dZ.shape))\n",
        "  dW = 1/m * np.dot( A_prev.T, dZ )\n",
        "  db = 1/m * np.sum(dZ, axis=0, keepdims=True)\n",
        "  return dZ, dW, db\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E6qNK4UoANY"
      },
      "source": [
        "def calculate_cost(params, Y, m):\n",
        "  Y = np.array(Y)\n",
        "  cost = -(1/m) * np.sum(Y * np.log(params[\"A4\"]) + (1-Y) * np.log(1-params[\"A4\"]))\n",
        "  return cost\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnLKaOzdmvst"
      },
      "source": [
        "def fc(input, layer_dim: list, action: ActivationType, Y, m):\n",
        "  parameters = {}\n",
        "  X = input.reshape(input.shape[0],-1)\n",
        "  dim = layer_dim\n",
        "  dim.insert(0, X.shape[1])\n",
        "  J_reg = 0\n",
        "  parameters[\"A0\"] = X\n",
        "  for l in range(1, len(dim)):\n",
        "    parameters[\"W\"+str(l)] = np.random.randn(dim[l-1], dim[l]) * 0.01\n",
        "    parameters[\"b\"+str(l)] = np.zeros((1, dim[l]))\n",
        "\n",
        "    Z, A = forward_propagation(parameters[\"A\"+str(l-1)], parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], ActivationType.Sigmoid)\n",
        "    parameters[\"Z\"+str(l)] = Z\n",
        "    parameters[\"A\"+str(l)] = A\n",
        "    # print(\"{} = W -> {}\\t b -> {}\\t z -> {}\\t A -> {}\".format(l, parameters[\"W\"+str(l)].shape, parameters[\"b\"+str(l)].shape, parameters[\"Z\"+str(l)].shape, parameters[\"A\"+str(l)].shape))\n",
        "    \n",
        "  for l in range(len(dim) - 1, 0, -1):\n",
        "    # print(\"reversed L \", l)\n",
        "    dZ, dW, db = backward_propagation(parameters, l, Y, m, len(dim)-1)\n",
        "    parameters[\"dZ\"+str(l)] = dZ\n",
        "    parameters[\"dW\"+str(l)] = dW\n",
        "    parameters[\"db\"+str(l)] = db\n",
        "    # print(\"dZ{} = {}\\t dW{} = {}\\t \".format(l, parameters[\"dZ\"+str(l)].shape, l, parameters[\"dW\"+str(l)].shape))\n",
        "  \n",
        "  for i in range(1, len(dim)):\n",
        "    # print(\"{} = dW -> {}\\t db -> {}\\t dz -> {}\\t A -> {}\".format(i, parameters[\"dW\"+str(i)].shape, parameters[\"db\"+str(i)].shape, parameters[\"dZ\"+str(i)].shape, parameters[\"A\"+str(i)].shape))\n",
        "    parameters[\"W\"+str(i)] -= 0.01 * parameters[\"dW\"+str(i)]\n",
        "    parameters[\"b\"+str(i)] -= 0.01 * parameters[\"db\"+str(i)]\n",
        "\n",
        "  J = calculate_cost(parameters, Y, m)\n",
        "\n",
        "  for l in range(1, len(dim)):\n",
        "    J_reg += (0.001 / (2 * 60000)) * (np.sum(parameters['W' + str(l)] ** 2))\n",
        "    J += J_reg\n",
        "  \n",
        "  # accuracy\n",
        "  ypred = np.round(parameters['A4'])\n",
        "  # print(\" predict => \", ypred.argmax(), \" actual => \",y_i.argmax())\n",
        "  return parameters"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9gynhCSPvMA",
        "outputId": "4e03b76f-5fa7-4772-f57d-4cfe6a73551a"
      },
      "source": [
        "image = np.random.randn(10,64,64,3)\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "Y = np.zeros((y_train.shape[0], 10))\n",
        "for idnx in range(y_train.shape[0]):\n",
        "  active_indx = y_train[idnx]\n",
        "  Y[idnx][active_indx] = 1\n",
        "print( y_train.shape, np.unique(y_train), y_train[1])\n",
        "for epoch in range(100):\n",
        "  acc = 0\n",
        "  for i in range (60000):\n",
        "    x_i = x_train[i, :]\n",
        "    y_i = Y[i, :]\n",
        "    # x_i = x_i.reshape((len(x_i), 1))\n",
        "    # y_i = y_i.reshape((len(y_i), 1))\n",
        "    param = fc(x_i, [40,30,20,10], ActivationType.Softmax, y_i, x_train.shape[0])\n",
        "    ypred = np.round(param['A4'])\n",
        "    if ypred.argmax() == y_i.argmax():\n",
        "      acc += 1\n",
        "  print(\"Epoch \", epoch, \" acc ==> \", round(acc * 100 / x_train.shape[0], 3))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,) [0 1 2 3 4 5 6 7 8 9] 0\n",
            "Epoch  0  acc ==>  10.197\n",
            "Epoch  1  acc ==>  10.302\n",
            "Epoch  2  acc ==>  10.187\n",
            "Epoch  3  acc ==>  10.317\n",
            "Epoch  4  acc ==>  10.367\n",
            "Epoch  5  acc ==>  10.317\n",
            "Epoch  6  acc ==>  10.312\n",
            "Epoch  7  acc ==>  10.232\n",
            "Epoch  8  acc ==>  10.298\n",
            "Epoch  9  acc ==>  10.362\n",
            "Epoch  10  acc ==>  10.212\n",
            "Epoch  11  acc ==>  10.088\n",
            "Epoch  12  acc ==>  10.295\n",
            "Epoch  13  acc ==>  9.988\n",
            "Epoch  14  acc ==>  10.06\n",
            "Epoch  15  acc ==>  10.41\n",
            "Epoch  16  acc ==>  10.408\n",
            "Epoch  17  acc ==>  10.068\n",
            "Epoch  18  acc ==>  10.017\n",
            "Epoch  19  acc ==>  10.218\n",
            "Epoch  20  acc ==>  10.135\n",
            "Epoch  21  acc ==>  10.217\n",
            "Epoch  22  acc ==>  10.19\n",
            "Epoch  23  acc ==>  10.07\n",
            "Epoch  24  acc ==>  10.027\n",
            "Epoch  25  acc ==>  10.132\n",
            "Epoch  26  acc ==>  10.377\n",
            "Epoch  27  acc ==>  10.277\n",
            "Epoch  28  acc ==>  10.098\n",
            "Epoch  29  acc ==>  10.4\n",
            "Epoch  30  acc ==>  10.048\n",
            "Epoch  31  acc ==>  10.1\n",
            "Epoch  32  acc ==>  10.198\n",
            "Epoch  33  acc ==>  10.443\n",
            "Epoch  34  acc ==>  10.273\n",
            "Epoch  35  acc ==>  10.288\n",
            "Epoch  36  acc ==>  10.02\n",
            "Epoch  37  acc ==>  10.213\n",
            "Epoch  38  acc ==>  10.32\n",
            "Epoch  39  acc ==>  10.292\n",
            "Epoch  40  acc ==>  10.117\n",
            "Epoch  41  acc ==>  10.315\n",
            "Epoch  42  acc ==>  10.108\n",
            "Epoch  43  acc ==>  10.242\n",
            "Epoch  44  acc ==>  10.218\n",
            "Epoch  45  acc ==>  10.3\n",
            "Epoch  46  acc ==>  10.395\n",
            "Epoch  47  acc ==>  10.098\n",
            "Epoch  48  acc ==>  10.165\n",
            "Epoch  49  acc ==>  10.167\n",
            "Epoch  50  acc ==>  10.305\n",
            "Epoch  51  acc ==>  10.38\n",
            "Epoch  52  acc ==>  10.353\n",
            "Epoch  53  acc ==>  10.41\n",
            "Epoch  54  acc ==>  10.43\n",
            "Epoch  55  acc ==>  10.257\n",
            "Epoch  56  acc ==>  10.257\n",
            "Epoch  57  acc ==>  10.225\n",
            "Epoch  58  acc ==>  10.318\n",
            "Epoch  59  acc ==>  10.073\n",
            "Epoch  60  acc ==>  10.113\n",
            "Epoch  61  acc ==>  10.32\n",
            "Epoch  62  acc ==>  10.308\n",
            "Epoch  63  acc ==>  10.38\n",
            "Epoch  64  acc ==>  10.198\n",
            "Epoch  65  acc ==>  10.273\n",
            "Epoch  66  acc ==>  10.277\n",
            "Epoch  67  acc ==>  10.147\n",
            "Epoch  68  acc ==>  10.217\n",
            "Epoch  69  acc ==>  10.228\n",
            "Epoch  70  acc ==>  10.223\n",
            "Epoch  71  acc ==>  10.187\n",
            "Epoch  72  acc ==>  10.252\n",
            "Epoch  73  acc ==>  10.288\n",
            "Epoch  74  acc ==>  10.17\n",
            "Epoch  75  acc ==>  10.232\n",
            "Epoch  76  acc ==>  10.157\n",
            "Epoch  77  acc ==>  10.272\n",
            "Epoch  78  acc ==>  10.24\n",
            "Epoch  79  acc ==>  10.21\n",
            "Epoch  80  acc ==>  10.218\n",
            "Epoch  81  acc ==>  10.228\n",
            "Epoch  82  acc ==>  10.173\n",
            "Epoch  83  acc ==>  9.933\n",
            "Epoch  84  acc ==>  10.345\n",
            "Epoch  85  acc ==>  10.255\n",
            "Epoch  86  acc ==>  10.278\n",
            "Epoch  87  acc ==>  10.277\n",
            "Epoch  88  acc ==>  10.227\n",
            "Epoch  89  acc ==>  10.105\n",
            "Epoch  90  acc ==>  10.332\n",
            "Epoch  91  acc ==>  10.102\n",
            "Epoch  92  acc ==>  10.287\n",
            "Epoch  93  acc ==>  10.353\n",
            "Epoch  94  acc ==>  10.337\n",
            "Epoch  95  acc ==>  10.115\n",
            "Epoch  96  acc ==>  10.423\n",
            "Epoch  97  acc ==>  10.098\n",
            "Epoch  98  acc ==>  10.153\n",
            "Epoch  99  acc ==>  10.123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6LH-VgoYMhd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}